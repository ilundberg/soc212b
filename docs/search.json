[
  {
    "objectID": "who_we_are.html",
    "href": "who_we_are.html",
    "title": "Who We Are",
    "section": "",
    "text": "Get to know a little bit about our teaching team!\n\n\n\n\n\n\n\n\nIan Lundberg\nianlundberg@ucla.edu\n(he / him)\nWorking with data to understand inequality brings me joy! I am excited about causal inference and finding new research questions and ways to answer them. Other joys of mine include hiking, surfing, and oatmeal with blueberries.\n\n\n\n\n\n\n\n\nSoonhong Cho\ntnsehdtm@gmail.com\n(he / him)\nSoonhong is a PhD candidate in political science at UCLA."
  },
  {
    "objectID": "scales.html",
    "href": "scales.html",
    "title": "Scale construction",
    "section": "",
    "text": "To be written. This is not a central topic of the course, but will have an appendix page since it may be relevant to student projects.",
    "crumbs": [
      "Problem Sets",
      "Additional topics",
      "Scale construction"
    ]
  },
  {
    "objectID": "problem_sets.html",
    "href": "problem_sets.html",
    "title": "Problem Sets",
    "section": "",
    "text": "This page will contain a problem set corresponding to each class meeting. The problem sets are very open-ended and are designed to connect the material from class to your ongoing project.\nFor every problem set, submit a PDF. If your code is not embedded in your PDF, then also submit a code file.\nWe will discuss the weekly pattern in our first meeting. A proposed pattern is:\nWe will be using identified peer reviews. The reason these are not anonymous is that we are a small class, and we will get to know one another’s projects. Your peer reviewer will not be grading you or assigning point values, but they will be commenting on your work. A good peer review is a short paragraph that comments on promising aspects of your peer’s work as well as offering suggestions for improvement or future directions."
  },
  {
    "objectID": "problem_sets.html#problem-set-1",
    "href": "problem_sets.html#problem-set-1",
    "title": "Problem Sets",
    "section": "Problem Set 1",
    "text": "Problem Set 1\n\n1. Your ongoing paper.\n1.1. (15 points) Write an abstract of your research paper.\n1.2. (5 points) What is one unit-specific quantity in your paper?\n1.3. (5 points) What is one target population in your paper?\n\n\n2. Regression for a conditional mean\n(25 points)\nIn class, we used OLS regression to predict the mean outcome in a subgroup. Do the same thing in a dataset of your choosing, which might be the dataset from your project. Define the outcome variable and the population subgroup you are describing."
  },
  {
    "objectID": "panel_data.html",
    "href": "panel_data.html",
    "title": "Panel data",
    "section": "",
    "text": "This page will cover forecasting, interrupted time series, difference in difference, and fixed effects.",
    "crumbs": [
      "Problem Sets",
      "Non-Probability Samples and Observational Causal Inference",
      "Panel data"
    ]
  },
  {
    "objectID": "missing_data.html",
    "href": "missing_data.html",
    "title": "Missing data",
    "section": "",
    "text": "To be written. This is not a central topic of the course, but will have an appendix page since it may be relevant to student projects.",
    "crumbs": [
      "Problem Sets",
      "Additional topics",
      "Missing data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome to UCLA SOCIOL 212B (Winter 2025). See the syllabus.\nW 9–11:50am. Powell 320B.\nThis course is about answering social science questions using quantitative data. We will especially focus on how computational power is transforming the ways we can carry out quantitative research, covering both statistical and machine learning tools from the perspective of social science applications. The course especially emphasizes how to translate social science theories into quantities that can be estimated by algorithms designed for prediction. We will consider prediction in the service of both description and causal inference, building on ideas from SOCIOL 212A. The end product of the course is an extended abstract containing data analysis using the ideas from the course. For students continuing to 212C, the abstract can serve as the basis for the research project in that course. Students will leave the course prepared to connect social science theories to empirical evidence that can be produced by algorithms designed for prediction."
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "Welcome!",
    "section": "Learning goals",
    "text": "Learning goals\nStudents will learn to\n\ndefine a precise quantitative research question\nconnect that question to predictions that can be made by statistical or machine learning algorithms\nmake a principled argument for the choice of a particular learning approach"
  },
  {
    "objectID": "index.html#schedule-of-topics-tentative",
    "href": "index.html#schedule-of-topics-tentative",
    "title": "Welcome!",
    "section": "Schedule of topics (tentative)",
    "text": "Schedule of topics (tentative)\nPart 1. Descriptive data science with probability samples.\n\nJan 8. Asking research questions without \\(\\hat\\beta\\) and regression for \\(\\hat{Y}\\)\nJan 15 and 22. Algorithms for prediction\nJan 29. Data-driven selection of an estimator\nFeb 5. Panel data (actually a Part 2 topic, presented out of order to align with afternoon CCPR workshop)\nFeb 12. Statistical uncertainty by resampling\n\nPart 2. Non-probability samples and observational causal inference\n\nFeb 19. Nonparametric identification\nFeb 26. Estimation by prediction\nMar 5. Estimation by weighting\nMar 12. Doubly-robust estimation"
  },
  {
    "objectID": "index.html#who-should-take-this-course",
    "href": "index.html#who-should-take-this-course",
    "title": "Welcome!",
    "section": "Who should take this course?",
    "text": "Who should take this course?\nThe course is designed to support the development of quantitative social science research projects. The course is a good fit for PhD students in sociology, statistics, political science, economics, and other social sciences. PhD students from disciplines other than sociology should request a code from the instructor to enroll."
  },
  {
    "objectID": "index.html#prerequisite",
    "href": "index.html#prerequisite",
    "title": "Welcome!",
    "section": "Prerequisite",
    "text": "Prerequisite\nFamiliarity with basic probability and statistics (e.g., random variables, expectation, confidence intervals). Soc 212A is formally a prerequisite, but students who did not take Soc 212A are welcome to talk with me about whether Soc 212B would be a good fit for them."
  },
  {
    "objectID": "index.html#instructional-format",
    "href": "index.html#instructional-format",
    "title": "Welcome!",
    "section": "Instructional format",
    "text": "Instructional format\nLecture with in-class exercises. Bring computers to class."
  },
  {
    "objectID": "index.html#course-readings",
    "href": "index.html#course-readings",
    "title": "Welcome!",
    "section": "Course readings",
    "text": "Course readings\nReadings will be available online for free. See the course website for an updated schedule of readings and topics.\nMany readings from books with free PDFs available online:\n\nEfron, B., & T Hastie. 2016. Computer Age Statistical Inference: Algorithms, Evidence and Data Science. Cambridge: Cambridge University Press.\nHastie, T., R. Tibshirani, & J. Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. New York: Springer.\nHernán, M.A., & J.M. Robins. 2024. Causal Inference: What If? Boca Raton: Chapman & Hall / CRC."
  },
  {
    "objectID": "index.html#statistical-software",
    "href": "index.html#statistical-software",
    "title": "Welcome!",
    "section": "Statistical software",
    "text": "Statistical software\nYou can use any statistical software you prefer. I use R and will best be able to support you in R. In addition to R, we will attempt to provide Stata support where possible. Not all algorithms are available in Stata. If you are fluent in another software, you are welcome to use that. The focus of this course is on conceptual ideas, not a programming language."
  },
  {
    "objectID": "data_driven_selection.html",
    "href": "data_driven_selection.html",
    "title": "Data-driven selection of a prediction function",
    "section": "",
    "text": "To be written.",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Data-driven selection of an estimator"
    ]
  },
  {
    "objectID": "algorithms_for_prediction.html",
    "href": "algorithms_for_prediction.html",
    "title": "Algorithms for prediction",
    "section": "",
    "text": "For two sessions, we will cover a few algorithms for prediction. We aim to",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Algorithms for prediction"
    ]
  },
  {
    "objectID": "algorithms_for_prediction.html#penalized-regression",
    "href": "algorithms_for_prediction.html#penalized-regression",
    "title": "Algorithms for prediction",
    "section": "Penalized regression",
    "text": "Penalized regression",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Algorithms for prediction"
    ]
  },
  {
    "objectID": "algorithms_for_prediction.html#multilevel-models",
    "href": "algorithms_for_prediction.html#multilevel-models",
    "title": "Algorithms for prediction",
    "section": "Multilevel models",
    "text": "Multilevel models",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Algorithms for prediction"
    ]
  },
  {
    "objectID": "algorithms_for_prediction.html#trees",
    "href": "algorithms_for_prediction.html#trees",
    "title": "Algorithms for prediction",
    "section": "Trees",
    "text": "Trees",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Algorithms for prediction"
    ]
  },
  {
    "objectID": "algorithms_for_prediction.html#forests",
    "href": "algorithms_for_prediction.html#forests",
    "title": "Algorithms for prediction",
    "section": "Forests",
    "text": "Forests",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Algorithms for prediction"
    ]
  },
  {
    "objectID": "algorithms_for_prediction.html#gradient-boosting",
    "href": "algorithms_for_prediction.html#gradient-boosting",
    "title": "Algorithms for prediction",
    "section": "Gradient boosting",
    "text": "Gradient boosting",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Algorithms for prediction"
    ]
  },
  {
    "objectID": "asking_a_research_question.html",
    "href": "asking_a_research_question.html",
    "title": "Asking a research question",
    "section": "",
    "text": "slides\nThis class is about how to ask a quantitative research question. The focus will be on summarizing outcomes over well-defined populations, for which a regression coefficient \\(\\hat\\beta\\) may or may not be a meaningful summary. We will focus on summarizing subgroups by the average value of \\(Y\\), or in small samples by summarizing subgroup means using predicted values (\\(\\hat{Y}\\)) from regression models.",
    "crumbs": [
      "Problem Sets",
      "Asking a Research Question"
    ]
  },
  {
    "objectID": "doubly_robust.html",
    "href": "doubly_robust.html",
    "title": "Doubly-robust estimation",
    "section": "",
    "text": "This session will combine prediction and weighting methods for an approach with properties superior to either on its own.",
    "crumbs": [
      "Problem Sets",
      "Non-Probability Samples and Observational Causal Inference",
      "Doubly-robust estimation"
    ]
  },
  {
    "objectID": "mediation.html",
    "href": "mediation.html",
    "title": "Mediation",
    "section": "",
    "text": "To be written. This is not a central topic of the course, but will have an appendix page since it may be relevant to student projects.",
    "crumbs": [
      "Problem Sets",
      "Additional topics",
      "Mediation"
    ]
  },
  {
    "objectID": "nonparametric_identification.html",
    "href": "nonparametric_identification.html",
    "title": "Nonparametric Identification",
    "section": "",
    "text": "This page will cover nonparametric identification of causal and population parameters. To be written.",
    "crumbs": [
      "Problem Sets",
      "Non-Probability Samples and Observational Causal Inference",
      "Nonparametric identification"
    ]
  },
  {
    "objectID": "prediction_for_inference.html",
    "href": "prediction_for_inference.html",
    "title": "Prediction for causal and population inference",
    "section": "",
    "text": "This session will be about prediction to draw population inference from non-probability samples and causal inference from observational studies, both of which involve analogous assumptions and estimators. If you have a Census with features \\(\\vec{X}\\), ignorable sampling conditional on \\(\\vec{X}\\), and a good sample estimator of \\(E(Y\\mid\\vec{X})\\) then you can predict \\(E(Y\\mid\\vec{X})\\) and aggregate over the Census-known population distribution of \\(\\vec{X}\\). For causal inference, being assigned to treatment is analogous to being sampled to observe the potential outcome under treatment.",
    "crumbs": [
      "Problem Sets",
      "Non-Probability Samples and Observational Causal Inference",
      "Estimation by prediction"
    ]
  },
  {
    "objectID": "resampling.html",
    "href": "resampling.html",
    "title": "Statistical Uncertainty: Bootstrap and Beyond",
    "section": "",
    "text": "As researchers adopt algorithmic estimation methods for which analytical standard errors do not exist, methods to produce standard errors by resampling become all the more important. We will discuss the bootstrap for simple random samples and extensions to allow resampling-based standard error estimates in complex survey samples.",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Statistical uncertainty by resampling"
    ]
  },
  {
    "objectID": "weighting_for_inference.html",
    "href": "weighting_for_inference.html",
    "title": "Weighting for causal and population inference",
    "section": "",
    "text": "This session will be about weighting to draw population inference from non-probability samples and causal inference from observational studies, both of which involve analogous assumptions and estimators.",
    "crumbs": [
      "Problem Sets",
      "Non-Probability Samples and Observational Causal Inference",
      "Estimation by weighting"
    ]
  },
  {
    "objectID": "yhat_regression.html",
    "href": "yhat_regression.html",
    "title": "Regression for Y-hat",
    "section": "",
    "text": "slides\nThis class is about regression as a tool to approximate a conditional expectation function. From this perspective, the \\(\\hat\\beta\\) estimates are only a step toward the broader purpose of regression to produce \\(\\hat{Y}\\) values that achieve this approximation well. This perspective will ultimately allow us to consider machine learning estimators beyond regression.\nSome of this class relies on an ongoing project on description: ilundberg.github.io/description",
    "crumbs": [
      "Problem Sets",
      "Descriptive Data Science with Probability Samples",
      "Regression for Y-hat"
    ]
  }
]