{
  "hash": "76aebee835af7d0d6cbca1ce329d7f93",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Doubly Robust Slides\"\nformat: beamer\n---\n\n\n\n<!-- Class plan\n- discuss open project questions\n- walk through example again\n- doubly robust in math\n- see what terms are zero in each case\n- doubly robust in code\n- TMLE in visuals / math / code\n- why would the line be flat if outcome model correct?\n- flyover of course\n- brainstorm topics for 212c\n-->\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## A motivating example\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-2-1.pdf)\n:::\n:::\n\n\n\n##\n\n$$\\tau = \\frac{1}{n_\\text{Not Surfed}}\\sum_{i:A_i=\\text{Not Surfed}} \\left(Y_i^\\text{Surfed} - Y_i^\\text{Not Surfed}\\right)$$\n\n##\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-3-1.pdf)\n:::\n:::\n\n\n\n##\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-4-1.pdf)\n:::\n:::\n\n\n\n##\n\nWe are always the child\n\n* model is too simple for the world\n* model is always wrong\n\n##\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-5-1.pdf)\n:::\n:::\n\n\n\nTo be even more concrete, consider 5-foot wave days. The child knows that they surfed only 10\\% of these days. Every day surfed really stands in for 9 days not surfed. If we were estimating the average treatment effect on the untreated by weighting, we would weight the 5-foot day by $\\text{P}(\\text{Not Surfed}\\mid X = 5) / \\text{P}(\\text{Surfed} \\mid X = 5) = .9 / .1 = 9$. We therefore might estimate the weighted error of the linear model, weighted by these weights.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-6-1.pdf)\n:::\n:::\n\n\n\nIn this case, the unweighted average error is 0 which is unsurprising: in OLS the average error in the training data is always 0! But here the goal is to predict in a shifted distribution of wave height. The inverse-probability-weighted error estimates the error on average over the space where we are making predictions: the model predictions are on average 1.34 points too high.\n\n## Augmented inverse probability weighting\n\nIf the child corrected for the error, they would be using an augmented inverse probability weighting estimator.\n\n$$\n\\hat\\tau_\\text{AIPW} = \\frac{1}{n_\\text{Not Surfed}}\\sum_{i:A_i=\\text{Not Surfed}} \\left(\\hat{Y}_i^1 - Y_i\\right) - \\frac{\\sum_{i:A_i=\\text{Surfed}} w_iY_i}{\\sum_{i:A_i=\\text{Surfed}} w_i}\n$$\nwhere $w_i$ is the inverse probability weight for estimating the average treatment effect on the untreated.\n\n$$\nw_i = \\frac{\\text{P}(A=\\text{Not Surfed}\\mid X = x_i)}{\\text{P}(A=\\text{Surfed} \\mid X = x_i)}\n$$\n\nIn this example, the outcome model is misspecified (a line for a parabola) but the weights are correct. Below, we see that the weights allow us to correct the wrong outcome model. First, we calculate the truth because in the simulation we know the potential outcomes.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  true_atc\n     <dbl>\n1      1.6\n```\n\n\n:::\n:::\n\n\n\nThen we calculate an initial estimate via outcome modeling.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  initial_estimate\n             <dbl>\n1             2.94\n```\n\n\n:::\n:::\n\n\n\nThird, we estimate the weighted mean error in the observed data.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  weighted_mean_error\n                <dbl>\n1                1.34\n```\n\n\n:::\n:::\n\n\n\nFinally, our corrected estimate is the initial estimate with the weighted mean error subtracted.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 3\n  initial_estimate weighted_mean_error corrected_estimate\n             <dbl>               <dbl>              <dbl>\n1             2.94                1.34                1.6\n```\n\n\n:::\n:::\n\n\n\nIn this case, the corrected estimate equals the true average treatment effect among the untreated! This numerical equivalence occurs because this simulation has known propensity scores and zero random error.\n\n### Double robustness\n\nThe example above illustrates a key property of the AIPW estimator: it is doubly robust, meaning that it is a consistent estimator as long as either\n\n\n* the model for treatment probabilities is consistent at each value of $\\vec{X}$, or\n* the model for potential outcomes is consistent at each value of $\\vec{X}$\n\nBelow, we consider each of these in turn.\n\nThe example above illustrated the first property: as long as the estimator of the treatment probabilities is consistent for the true probabilities of treatment, then the AIPW estimator is consistent for the truth. This is true even if the outcome model is wrong, as shown by the child's line above!\n\n$$\n\\begin{aligned}\n&\\text{if}\\quad &&\\hat{\\text{P}}(A = 1 \\mid\\vec{X} = \\vec{x})\\rightarrow \\text{P}(A = 1 \\mid\\vec{X} = \\vec{x})\\quad \\text{ for all }\\vec{x},\\\\\n&\\text{then}\\qquad &&\\hat\\tau_{\\text{AIPW}}\\rightarrow \\tau\n\\end{aligned}\n$$\n\nAlthough not illustrated above, the AIPW estimator is also correct if the outcome model is correct and the treatment model is wrong. To illustrate this, consider that at every value of $\\vec{X}$ an outcome model will be correct on average. Thus in a large sample, the average error at every value of $\\vec{X}$ will be 0. No matter how we take a weighted average across the $\\vec{X}$ values, the AIPW correction will always be 0! Thus the correct outcome model estimate will remain.\n\n$$\n\\begin{aligned}\n&\\text{if}\\quad &&\\hat{\\text{E}}(Y\\mid A = 1, \\vec{X} = \\vec{x})\\rightarrow \\text{E}(Y\\mid A = 1, \\vec{X} = \\vec{x})\\quad \\text{ for all }\\vec{x},\\\\\n&\\text{then}\\qquad &&\\hat\\tau_{\\text{AIPW}}\\rightarrow \\tau\n\\end{aligned}\n$$\n\n## Targeted learning\n\nAIPW is not the only way to update a model. Another option is called targeted learning ([Van der Laan and Rose 2011](https://link.springer.com/book/10.1007/978-1-4419-9782-1)). We first introduce targeted learning through one concrete example, then generalize the procedure in the sections that follows.\n\n### Modeling $Y^1$ for the ATC\n\nIn the surfing example, our goal is to estimate the mean outcome under surfing, for the observations on days when there was surfing. We begin with the child's initial fit: linear regression. Following notation that is common in targeted learning,^[The targeted learning literature typically uses $Q^0$ instead of $\\hat{Q}^0$, but we use the hat for consistency within this webpage that estimated quantities always have hats.] we will refer to this regression line as $\\hat{Q}^0$,\n\n$$\n\\underbrace{\\hat{Q}^0(\\vec{x})}_{\\substack{\\text{The 0 superscript}\\\\\\text{indicates an untargeted}\\\\\\text{initial estimate}}} = \\hat{\\text{E}}(Y\\mid A = 1, \\vec{X}) = \\hat\\alpha + \\hat\\beta\\vec{x}\n$$\n\nwhere $\\hat\\alpha$ and $\\hat\\beta$ are the OLS coefficients when modeling $Y$ given $X$ among the treated observations.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-12-1.pdf)\n:::\n:::\n\n\n\nThe child's model is targeted toward the observed data, but our target is actually to predict the counterfactual under surfing for the observations when the child did not surf. These are disproportionately at the right side of the figure. If we were estimating by inverse probability weighting, we would weight each treated observation by the ratio of untreated to treated observations given $X$. For targeted learning, we will call this a \"clever covariate\" that we will define as function $H()$.\n\n$$\nH(x) = \\frac{\\text{P}(A = \\text{Not Surfed} \\mid X = x)}{\\text{P}(A = \\text{Surfed}\\mid X = x)}\n$$\n\n\n::: {.cell}\n\n:::\n\n\n\nThe problem of non-targeted estimation is that our model errors are systematically related to the importance of each observation. To visualize this, create a graph with the clever covariate on the $x$-axis and the initial estimate errors on the $y$-axis.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-14-1.pdf)\n:::\n:::\n\n\n\nThe graph shows that the observed $Y$ values (awesomeness of the day) were especially far below the predicted $Y$-values at the right side of the graph: big-wave days when the clever covariate is very large. The regression line is a best-fit line for the errors with intercept restricted to equal 0. Equivalently, it is a best-fit line for $Y$ with the initial prediction $\\hat{Q}^0(X)$ included as an offset (an intercept with coefficient restricted to equal 1). The latter interpretation will be useful for generalizations.\n\n$$\n\\hat{\\text{E}}^1(Y\\mid X = x) = \\hat{Q}^1(x) = \\hat{Q}^0(x) + \\hat\\gamma \\underbrace{\\left(\\frac{\\text{P}(A = \\text{Not surfed}\\mid X = x)}{\\text{P}(A = \\text{Surfed}\\mid X = x)}\\right)}_{\\text{Clever covariate }h(x)}\n$$\n\nNow we return to our goal: estimating the counterfactual awesomeness of non-surfing days if the child had surfed on those days. We can now make two estimates, each of which compares the predicted outcomes under surfing ($\\hat{Q}^0(x)$ and $\\hat{Q}^1(x)$) to the observed outcomes under no surfing.\n\n$$\n\\begin{aligned}\n\\text{Initial estimate:}\\qquad &&\\hat\\tau^0 &= \\frac{1}{n_{\\text{NotSurfed}}}\\sum_{i:A_i=\\text{NotSurfed}}\\left(\\hat{Q}^0(x_i) - y_i\\right)\\\\\n\\text{Targeted estimate:}\\qquad &&\\hat\\tau^1 &= \\frac{1}{n_{\\text{NotSurfed}}}\\sum_{i:A_i=\\text{NotSurfed}}\\left(\\hat{Q}^1(x_i) - y_i\\right)\n\\end{aligned}\n$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|name                                   | Initial Estimate| Targeted Estimate| Truth (Y1 Not Observed)|\n|:--------------------------------------|----------------:|-----------------:|-----------------------:|\n|Mean Predicted Outcome Under Surfing   |              7.9|               6.6|                     6.6|\n|Mean Observed Outcome Under No Surfing |              5.0|               5.0|                     5.0|\n|Effect of Surfing                      |              2.9|               1.6|                     1.6|\n\n\n:::\n:::\n\n\n\n### Modeling both $Y^0$ and $Y^1$\n\nIn the section above, we focused on untreated cases and took the observed $Y$ values as $Y^0$ estimates instead of predicting from a regression model. More generally, we might be interested in both the treated and untreated cases (e.g., for an average treatment effect) and would need model-based estimates for both $Y^0$ and $Y^1$.\n\nWhen modeling both potential outcomes, we begin with an initial estimate of the conditional mean function: linear regresion estimated separately on the treated and untreated observations. As before, the 0 superscripts indicate that this is an initial estimate.\n\n$$\n\\begin{aligned}\n\\hat{Q}^0(a,\\vec{x}) &= \\hat{\\text{E}}^0(Y\\mid A = a, \\vec{X} = \\vec{x}) = \\begin{cases}\n\\hat\\alpha_0 + \\vec{x}'\\hat\\beta_0 &\\text{if }a = 0 \\\\\n\\hat\\alpha_1 + \\vec{x}'\\hat\\beta_1 &\\text{if }a = 1\n\\end{cases}\n\\end{aligned}\n$$\nIn code, we can estimate these two regression models\n\n\n\n::: {.cell}\n\n:::\n\n\n\nand construct the $\\hat{Q}^0$ function.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-18-1.pdf)\n:::\n:::\n\n\n\nUsing the $\\hat{Q}^0$ function, we can produce an initial estimate of the ATE.\n\n$$\n\\hat\\tau_\\text{ATE}^0 = \\underbrace{\\frac{1}{n}\\sum_i}_\\text{Sample average} \\bigg(\\underbrace{\\hat{Q}^0(1,x_i)}_{\\substack{\\text{Initial prediction}\\\\\\text{under treatment}}} - \\underbrace{\\hat{Q}^0(0,x_i)}_{\\substack{\\text{Initial prediction}\\\\\\text{under control}}}\\bigg)\n$$\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  initial_ate_estimate\n                 <dbl>\n1                 2.27\n```\n\n\n:::\n:::\n\n\n\nWe know that this estimate is wrong because of the misspecified outcome model optimized over the observed data instead of the data to be predicted. To correct this misspecification, we define the clever covariate.\n\n* because the goal is the ATE, this is the inverse probability of treatment\n* because we difference (treatment) -- (control), the control weight is negative\n\n$$\nH(a,x) = \\begin{cases}\n\\frac{1}{P(A = 1\\mid X)}&\\text{if }a=1 \\\\\n\\frac{-1}{P(A = 0\\mid X)}&\\text{if }a=0\n\\end{cases}\n$$\nTo create this in code, we first note the propensity scores which are known in this example,\n\n\n\n::: {.cell}\n\n:::\n\n\n\nand then we write an `h()` function.\n\n\n::: {.cell}\n\n:::\n\n\n\nThe graph below visualizes our $h$ values on the $x$-axis and the errors of our initial model on the $y$-axis, with a line that corresponds to the targeting step to be completed below.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](doubly_robust_part2_files/figure-beamer/unnamed-chunk-22-1.pdf)\n:::\n:::\n\n\n\nThe targeting fit visualized in the model above is the linear regression of $Y$ on $H(A,X)$ (the clever covariate, which involves inverse probability weights), estimated with offset equal to the intial predictions $Q^0(A,X)$.\n\n$$\n\\hat{Q}^1(A,\\vec{X}) = \\text{E}^1\\left(Y \\mid A, \\vec{X}\\right) = \\hat{Q}^0(A,\\vec{X}) + \\hat\\gamma H(A,\\vec{X})\n$$\n\nThe slope of the line in the figure above equals the coefficient estimate $\\hat\\gamma$ in the equation above. In code, below we estimate the targeting regresion model\n\n\n\n::: {.cell}\n\n:::\n\n\n\nand then write a `q1()` function that will return targeted predictions at treatment value `a` and confounder value `x`.\n\n\n\n::: {.cell}\n\n:::\n\n\n\nUsing the $\\hat{Q}^1$ function, we can produce a targeted estimate of the ATE.\n\n$$\n\\hat\\tau_\\text{ATE}^1 = \\underbrace{\\frac{1}{n}\\sum_i}_\\text{Sample average} \\bigg(\\underbrace{\\hat{Q}^1(1,x_i)}_{\\substack{\\text{Targeted prediction}\\\\\\text{under treatment}}} - \\underbrace{\\hat{Q}^0(1,x_i)}_{\\substack{\\text{Targeted prediction}\\\\\\text{under control}}}\\bigg)\n$$\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 x 1\n  targeted_ate_estimate\n                  <dbl>\n1                   1.6\n```\n\n\n:::\n:::\n\n\n\nBecause this example is constructed with no random noise and known treatment probabilities, the targeted ATE estimate exactly matches the true ATE of 1.6.\n\n### Why TMLE vs AIPW?\n\nWhy would one choose TMLE over AIPW?\n\nBoth approaches solve the same problem: when building an outcome model for $Y^1$, the model is learned over the confounder distribution $\\vec{X}\\mid A = 1$ among treated units, but the goal is to predict over the distribution $\\vec{X}\\mid A = 0$ among untreated units. When the outcome model is going to fit poorly in part of the space (e.g., due to model misspecification), then the first-stage model will optimize fit in the part of the space where it observes more data. But this may not be the same as the part of the space where predictions are to be made.\n\nAIPW and TMLE solve this problem in related but distinct ways. In AIPW, the outcome model is corrected by the weighted average error where weights equal inverse probability of treatment weights. In TMLE, the outcome model is corrected by a second-stage regression that uses inverse probability of treatment weights as a \"clever covariate\" in a regression model.\n\nUltimately, both approaches are doubly robust. One advantage of TMLE arises when the outcome is binary, because then the second-stage regression can be a generalized linear model where the TMLE correction occurs on the space of the linear predictor. Thus, TMLE can be constructed to enforce boundaries such as never predicting probabilities below 0 or greater than 1.\n\nIn practice, I have not seen a clear resolution in favor of one or the other approach, and both approaches are likely to be good estimators. Any doubly-robust method may be preferable to the more typical approach of relying entirely on an outcome or treatment model!\n\n<!-- ### TMLE with a binary outcome -->\n\n<!-- A benefit of TMLE is that it can be carried out with a binary outcome. -->\n\n\n\n<!-- Note: I tried to construct a setting where -->\n\n<!-- * treatment model is correctly specified -->\n<!-- * outcome model is incorrectly specified -->\n<!-- * AIPW makes an estimate outside (0,1) -->\n\n<!-- Other than a few numerical edge cases that may have come from logit not converging, I am not able to create such a simulation. I think this is analogous to how a linear probability model only leads to the problem of predicting outside the (0,1) interval when that model is incorrectly specified. -->\n\n<!-- ```{r} -->\n<!-- base_data <- tibble(x = c(rep(1:2, each = 99), 3), a = TRUE) |> -->\n<!--   bind_rows( -->\n<!--     tibble(x = c(1:2,rep(3, 99)), a = FALSE) -->\n<!--   ) -->\n<!-- base_data |> -->\n<!--   table() -->\n<!-- data <- base_data |> -->\n<!--   mutate( -->\n<!--     pi = case_when( -->\n<!--       x == 1 ~ .99, -->\n<!--       x == 2 ~ .99, -->\n<!--       x == 3 ~ .01 -->\n<!--     ), -->\n<!--     y1 = case_when( -->\n<!--       x == 1 ~ .5, -->\n<!--       x == 2 ~ .5, -->\n<!--       x == 3 ~ .9 -->\n<!--     ), -->\n<!--     y0 = 0, -->\n<!--     y = ifelse(a, y1, y0) -->\n<!--   ) -->\n\n<!-- fit <- lm(y ~ x, data = data |> filter(a)) -->\n\n<!-- correction <- data |> -->\n<!--   filter(a) |> -->\n<!--   mutate( -->\n<!--     error = predict(fit) - y, -->\n<!--     weight = (1 - pi) / pi -->\n<!--   ) |> -->\n<!--   summarize(correction = weighted.mean(error, w = weight)) |> -->\n<!--   print() -->\n\n<!-- data |>  -->\n<!--   filter(a) |> -->\n<!--   mutate(yhat = predict(fit, newdata = data |> filter(a))) |> -->\n<!--   mutate(weight = (1 - pi) / pi) |> -->\n<!--   ggplot(aes(x = x)) + -->\n<!--   geom_hline(yintercept = 1, linetype = \"dashed\") + -->\n<!--   geom_jitter(aes(y = y, size = weight), width = .1, height = .005, alpha = .2) + -->\n<!--   geom_line(aes(y = yhat)) + -->\n<!--   ylab(\"Observed Outcomes\\nof Treated Units\") + -->\n<!--   xlab(\"Confounder X\") + -->\n<!--   scale_size_continuous( -->\n<!--     name = \"Treatment\\nWeight for\\nATC\", -->\n<!--     breaks = c(.01,99), -->\n<!--     limits = c(.01,99) -->\n<!--   ) + -->\n<!--   labs( -->\n<!--     subtitle = paste( -->\n<!--       \"Weighted mean error:\\nLine is\", -->\n<!--       correction |> pull(correction) |> round(2), -->\n<!--       \"too low\" -->\n<!--     ) -->\n<!--   ) -->\n\n<!-- data |> -->\n<!--   filter(!a) |> -->\n<!--   mutate(initial = predict(fit, newdata = data |> filter(!a))) |> -->\n<!--   select(x, initial) |> -->\n<!--   mutate(corrected = initial - correction$correction) |> -->\n<!--   pivot_longer(cols = -x) |> -->\n<!--   ggplot(aes(x = x, y = value, linetype = name)) + -->\n<!--   geom_hline(yintercept = 1, linetype = \"dashed\") + -->\n<!--   geom_jitter(width = .1, height = .01, alpha = .2) + -->\n<!--   geom_line() -->\n\n<!-- # Run many times with sampling variability -->\n<!-- simulate <- function() { -->\n<!--   data_simulated <- data |> -->\n<!--     # Randomize Y from Bernoulli with existing probability -->\n<!--     mutate( -->\n<!--       y = rbinom(n(), 1, y) -->\n<!--     ) -->\n<!--   fit <- lm(y ~ x, data = data_simulated |> filter(a)) -->\n\n<!--   correction <- data_simulated |> -->\n<!--     filter(a) |> -->\n<!--     mutate( -->\n<!--       error = predict(fit) - y, -->\n<!--       weight = (1 - pi) / pi -->\n<!--     ) |> -->\n<!--     summarize(correction = weighted.mean(error, w = weight)) -->\n\n<!--   estimate <- data_simulated |> -->\n<!--     filter(!a) |> -->\n<!--     mutate(yhat1 = predict(fit, newdata = data_simulated |> filter(!a))) |> -->\n<!--     summarize(initial = mean(yhat1)) |> -->\n<!--     mutate(corrected = initial - correction$correction) -->\n<!--   return(estimate) -->\n<!-- } -->\n<!-- simulations <- foreach(r = 1:500, .combine = \"rbind\") %do% simulate() -->\n<!-- simulations |> -->\n<!--   pivot_longer(cols = everything()) |> -->\n<!--   ggplot(aes(x = value)) + -->\n<!--   geom_histogram() + -->\n<!--   facet_wrap(~name) -->\n\n<!-- simulations |> -->\n<!--   arrange(-corrected) -->\n<!-- ``` -->\n\n## Sample splitting for machine learning\n\nUnder classical statistical approaches to inference, one often worries about model misspecification. The problem of model misspecification is that if one approximates $\\text{E}(Y\\mid A, \\vec{X})$ by an additive regression and the true response function is nonlinear, then the model will be an inconsistent estimator of $\\text{E}(Y\\mid\\vec{X} = \\vec{x})$ for at least some $\\vec{x}$. Double robustness solves this problem: as long as $\\text{E}(Y\\mid\\vec{X})$ or $\\text{P}(A = 1\\mid\\vec{X})$ is estimated by a consistent estimator, then the causal effect estimate is consistent.\n\nMachine learning approaches seem to upend this logic: flexible models can be consistent estimators by construction. Without any assumption of a statistical model, a random forest can yield a consistent estimator of $\\text{E}(Y\\mid A,\\vec{X})$ and $\\text{P}(A = 1\\mid\\vec{X})$. By consistent, we mean that the forest would come to equal these estimands in an infinite sample. Does double robustness then have any use?\n\nThe problem with flexible machine learning estimators is that they converge to the true response surface at slower rates than parametric regression models. In finite samples, the estimators will be biased at some $\\vec{X} = \\vec{x}$ values due to regularization. Thus, the key to machine learning estimators is to do use the same doubly robust formulation, with a small twist.\n\n1. Using sample $\\mathcal{S}_1$, estimate two prediction functions\n$$\n\\begin{aligned}\n\\hat{g}(\\mathcal{S}_1,a,\\vec{x}) &= \\hat{\\text{E}}(Y\\mid A = a, \\vec{X} = \\vec{x}) \\\\\n\\hat{m}(\\mathcal{S}_1,a,\\vec{x}) &= \\hat{\\text{P}}(A = a \\mid \\vec{X} = \\vec{x}) \\\\\n\\end{aligned}\n$$\n\n2. In sample $\\mathcal{S}_2$, apply the AIPW estimator.\n$$\n\\begin{aligned}\n\\hat{\\text{E}}(Y^a) &= \\underbrace{\\frac{1}{\\lvert\\mathcal{S}_2\\rvert}\\sum_{i\\in\\mathcal{S}_2}\\hat{g}(\\mathcal{S}_1,a,\\vec{X}_i)}_{\\text{outcome modeling estimator}} - \n\\underbrace{\\frac{1}{\\sum_{i\\in\\mathcal{S}_2}\\frac{\\mathbb{I}(A_i=a)}{\\hat{m}(\\mathcal{S}_1, A_i,\\vec{X}_i)}}\\sum_{i\\in\\mathcal{S}_2}\\frac{\\mathbb{I}(A_i=a)\\bigg(\\hat{g}(\\mathcal{S}_1, A_i,\\vec{X}_i) - y_i\\bigg)}{\\hat{m}(\\mathcal{S}_1, A_i,\\vec{X}_i)}}_\\text{debiasing correction}\n\\end{aligned}\n$$\n\nIf we drop the normalizing constant on the weights in the debiasing correction (which on asymptotically equals the number of treated observations), we get an estimator that can be written as an empirical mean $\\hat{\\text{E}}_{\\mathcal{S}_2}$ over the cases in sample $\\mathcal{S}_2$.\n\n$$\n\\hat\\tau(a) = \\hat{\\text{E}}_{\\mathcal{S}_2}\\left(\n  \\hat{g}(\\mathcal{S}_1,a,\\vec{X})\n  -\n  \\frac{\\mathbb{I}(A=a)\\bigg(\\hat{g}(\\mathcal{S}_1, A,\\vec{X}) - Y\\bigg)}{\\hat{m}(\\mathcal{S}_1, A,\\vec{X})}\n\\right)\n$$\n\nWhen $\\hat{g}\\rightarrow g$ and $\\hat{m}\\rightarrow m$ at slower asymptotic rates than we ordinarily observe for linear regression, it is still possible for $\\hat\\tau\\rightarrow \\tau$ at the ordinary $\\sqrt{n}$ asymptotic rate. In other words, even if you estimate a $\\hat{g}$ and $\\hat{m}$ with random forests, it is possible for $\\hat\\tau$ to converge to the true expected potential outcome at a rate with good properties! A key for this to happen is that $\\hat{g}$ and $\\hat{m}$ are learned in a separate sample from the one in which they are applied.\n\n### Cross fitting\n\nSimilar to the move from a train-test split to cross-validation, one can make a similar move from sample splitting to a technique called cross fitting.\n\n1. In sample $\\mathcal{S}_1$, estimate the outcome model $g(\\mathcal{S}_1,a,\\vec{x})$ and treatment model $\\hat{m}(\\mathcal{S}_1,a)$.\n2. In sample $\\mathcal{S}_2$, produce an AIPW estimate.\n3. Repeat steps (1) and (2), swapping the roles of $\\mathcal{S}_1$ and $\\mathcal{S}_2$.\n4. Average the results.\n\n## Exercises\n\nCarry out the child's analysis by\n\n* an outcome model.\n* inverse probability weighting, with weights estimated by logistic regression\n* augmented inverse probability weighting\n\n<!-- Child's analysis by machine learning. -->\n\n<!-- ```{r} -->\n<!-- generate_data <- function(n = 90, noise = .1, replace = T) { -->\n<!--   tibble(x = rep(1:9,1:9), a = F) |> -->\n<!--     bind_rows(tibble(x = rep(1:9,9:1), a = T)) |> -->\n<!--     sample_n(n, replace = replace) |> -->\n<!--     mutate( -->\n<!--       y1 = 9 - 9 * ((x - 5) / 5) ^ 2, -->\n<!--       y0 = 5, -->\n<!--       # Shift x to fit story of this DGP -->\n<!--       x = (x - 1) / 2 + 1, -->\n<!--       y = case_when( -->\n<!--         !a ~ y0, -->\n<!--         a ~ y1 -->\n<!--       ) + runif(n(), -noise, noise) -->\n<!--     ) -->\n<!-- } -->\n<!-- ``` -->\n\n<!-- ### Statistical estimator -->\n\n<!-- ```{r} -->\n<!-- estimator <- function(n = 100) { -->\n<!--   full_data <- generate_data(n) -->\n<!--   g_fit <- glm(y ~ x + a, data = full_data) -->\n<!--   m_fit <- glm(a ~ x, data = full_data, family = binomial) -->\n\n<!--   set_to_treated <- full_data |> mutate(a = T) -->\n\n<!--   # Truth -->\n<!--   truth <- generate_data(noise = 0, replace = F) |> -->\n<!--     summarize(truth = mean(y1)) |> -->\n<!--     pull(truth) -->\n\n<!--   # Outcome modeling -->\n<!--   outcome_estimate <- set_to_treated |> -->\n<!--     mutate(ghat = predict(g_fit, newdata = set_to_treated)) |> -->\n<!--     summarize(estimate = mean(ghat)) |> -->\n<!--     pull(estimate) -->\n\n<!--   # IPW -->\n<!--   ipw_estimate <- full_data |> -->\n<!--     mutate(mhat = predict(m_fit, data = full_data, type = \"response\")) |> -->\n<!--     filter(a) |> -->\n<!--     summarize(estimate = weighted.mean(y, w = 1 / mhat)) |> -->\n<!--     pull(estimate) -->\n\n<!--   # Doubly robust estimator -->\n<!--   treated_cases <- full_data |> filter(a) -->\n<!--   correction <- treated_cases |> -->\n<!--     mutate( -->\n<!--       mhat = predict(m_fit, newdata = treated_cases, type = \"response\"), -->\n<!--       ghat = predict(g_fit, newdata = treated_cases) -->\n<!--     ) |> -->\n<!--     summarize( -->\n<!--       correction = weighted.mean( -->\n<!--         ghat - y, w = 1 / mhat -->\n<!--       ) -->\n<!--     ) |> -->\n<!--     pull(correction) -->\n\n<!--   tibble( -->\n<!--     outcome = outcome_estimate, -->\n<!--     ipw = ipw_estimate, -->\n<!--     dr = outcome_estimate - correction, -->\n<!--     truth = truth -->\n<!--   ) -->\n<!-- } -->\n<!-- ``` -->\n\n<!-- Repeat on many samples -->\n\n<!-- ```{r} -->\n<!-- results <- foreach(sample_size = c(seq(100,500,100)), .combine = \"rbind\") %do% { -->\n<!--   foreach(rep = 1:100, .combine = \"rbind\") %do% { -->\n<!--     estimator(n = sample_size) |> -->\n<!--       mutate(sample_size = sample_size) -->\n<!--   } -->\n<!-- } -->\n\n<!-- results |> -->\n<!--   select(-truth) |> -->\n<!--   pivot_longer(cols = -sample_size) |> -->\n<!--   ggplot(aes(x = sample_size, y = value, color = name)) + -->\n<!--   #geom_line() + -->\n<!--   geom_point() + -->\n<!--   facet_wrap(~name) -->\n\n<!-- results |> -->\n<!--   group_by(sample_size) |> -->\n<!--   summarize_all(mean) |> -->\n<!--   pivot_longer(cols = -sample_size) |> -->\n<!--   ggplot(aes(x = sample_size, y = value, color = name)) + -->\n<!--   geom_line() + -->\n<!--   geom_point() -->\n\n<!-- truth_value <- results$truth[1] -->\n<!-- results |> -->\n<!--   select(-truth) |> -->\n<!--   group_by(sample_size) |> -->\n<!--   summarize_all(\\(x) mean((x - truth_value) ^ 2)) |> -->\n<!--   pivot_longer(cols = -sample_size) |> -->\n<!--   ggplot(aes(x = sample_size, y = value, color = name)) + -->\n<!--   geom_line() + -->\n<!--   geom_point() + -->\n<!--   labs( -->\n<!--     y = \"Mean Squared Error\", -->\n<!--     x = \"Sample Size\", -->\n<!--     name = \"Estimator\" -->\n<!--   ) -->\n<!-- ``` -->\n\n\n<!-- ### Machine learning estimator -->\n\n<!-- ```{r} -->\n<!-- estimator <- function(n = 100) { -->\n<!--   full_data <- generate_data(n) -->\n<!--   g_fit <- ranger(y ~ x + a, data = full_data) -->\n<!--   m_fit <- ranger(as.numeric(a) ~ x, data = full_data) -->\n\n<!--   set_to_treated <- full_data |> mutate(a = T) -->\n\n<!--   # Truth -->\n<!--   truth <- generate_data(noise = 0, replace = F) |> -->\n<!--     summarize(truth = mean(y1)) -->\n\n<!--   # Outcome modeling -->\n<!--   outcome_estimate <- set_to_treated |> -->\n<!--     mutate(ghat = predict(g_fit, data = set_to_treated)$predictions) |> -->\n<!--     summarize(outcome_model_estimate = mean(ghat)) -->\n\n<!--   # IPW -->\n<!--   ipw_estimate <- full_data |> -->\n<!--     mutate(mhat = predict(m_fit, data = full_data)$predictions) |> -->\n<!--     filter(a) |> -->\n<!--     summarize(estimate = weighted.mean(y, w = 1 / mhat)) -->\n\n<!--   # Doubly robust estimator -->\n<!--   treated_cases <- full_data |> filter(a) -->\n<!--   correction <- treated_cases |> -->\n<!--     mutate( -->\n<!--       mhat = predict(m_fit, data = treated_cases)$predictions, -->\n<!--       ghat = predict(g_fit, data = treated_cases)$predictions -->\n<!--     ) |> -->\n<!--     summarize( -->\n<!--       correction = weighted.mean( -->\n<!--         ghat - y, w = 1 / mhat -->\n<!--       ) -->\n<!--     ) -->\n\n<!--   tibble( -->\n<!--     outcome = outcome_estimate$outcome_model_estimate, -->\n<!--     ipw = ipw_estimate$estimate, -->\n<!--     dr = outcome_estimate$outcome_model_estimate -  -->\n<!--       correction$correction, -->\n<!--     truth = truth$truth -->\n<!--   ) -->\n<!-- } -->\n<!-- ``` -->\n\n<!-- What happens as sample size grows? -->\n\n<!-- ```{r} -->\n<!-- results <- foreach(sample_size = c(250,500,1000,2000,4000), .combine = \"rbind\") %do% { -->\n<!--   foreach(rep = 1:10, .combine = \"rbind\") %do% { -->\n<!--     estimator(n = sample_size) |> -->\n<!--       mutate(sample_size = sample_size) -->\n<!--   } -->\n<!-- } -->\n<!-- results |> -->\n<!--   group_by(sample_size) |> -->\n<!--   summarize_all(mean) |> -->\n<!--   pivot_longer(cols = -sample_size) |> -->\n<!--   ggplot(aes(x = sample_size, y = value, color = name)) + -->\n<!--   geom_line() + -->\n<!--   geom_point() -->\n<!-- ``` -->\n\n<!-- # ```{r, echo = F} -->\n<!-- # data <- tibble( -->\n<!-- #   x = c(1,1,1,2,2,3,1,2,2,3,3,3), -->\n<!-- #   a = c(F,F,F,F,F,F,T,T,T,T,T,T), -->\n<!-- #   y = c(1,1,1,2,2,2,2,3,3,3,3,3) -->\n<!-- # ) |> -->\n<!-- #   group_by(x) |> -->\n<!-- #   mutate(pi = mean(a)) |> -->\n<!-- #   ungroup() -->\n<!-- #  -->\n<!-- # data |> -->\n<!-- #   ggplot(aes(x = x, y = y, color = a)) + -->\n<!-- #   geom_point() -->\n<!-- # ``` -->\n\n\n",
    "supporting": [
      "doubly_robust_part2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}